# Projeto 2: Detec√ß√£o de Anomalias em Tempo Real com Autoencoder (LSTM)

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![Streamlit](https://img.shields.io/badge/Streamlit-1.x-red?logo=streamlit)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.x-blueviolet?logo=scikit-learn)

## 1. Vis√£o Geral do Projeto

Este √© um projeto **end-to-end** de **Aprendizagem N√£o Supervisionada** focado na detec√ß√£o de anomalias em dados de sensores industriais. Diferente da manuten√ß√£o preditiva (que prev√™ *quando* uma falha conhecida ocorrer√°), este projeto foca em detectar *comportamentos estranhos e desconhecidos* no momento em que eles acontecem.

Utilizando o dataset **SKAB (Skoltech Anomaly Benchmark)**, um modelo Autoencoder baseado em LSTM √© treinado para "aprender" o comportamento normal de uma v√°lvula industrial. O resultado final √© um **Dashboard em tempo real (Streamlit)** que monitora um fluxo simulado de dados e dispara alertas visuais imediatos quando o comportamento do sistema se desvia da "normalidade".

## 2. O Problema de Neg√≥cio: Detectando o "Desconhecido"

Em sistemas industriais complexos, existem in√∫meras formas de falha. Enquanto a "Manuten√ß√£o Preditiva" (como no Projeto 1) √© excelente para prever falhas *conhecidas* (ex: desgaste de rolamento), ela falha em detectar eventos raros, s√∫bitos ou nunca antes vistos.

O desafio √©: **Como podemos detectar uma falha se n√£o temos dados de exemplo dessa falha para treinar o modelo?**

A solu√ß√£o √© a **Detec√ß√£o de Anomalias (Aprendizagem N√£o Supervisionada)**. Em vez de treinar o modelo para reconhecer falhas, n√≥s o treinamos para ser um "especialista" em reconhecer a opera√ß√£o *normal*. Qualquer dado que o especialista n√£o reconhe√ßa √©, por defini√ß√£o, uma anomalia.

## 3. A Solu√ß√£o de Machine Learning: O Autoencoder

A arquitetura do **Autoencoder** √© perfeitamente adequada para isso. O modelo funciona como um "funil":

1.  **Encoder (Codificador):** Comprime os dados de entrada (ex: 20 ciclos com 8 sensores) em uma representa√ß√£o compacta (um "gargalo" ou *bottleneck*). Isso for√ßa o modelo a aprender a ess√™ncia dos dados, descartando o ru√≠do.
2.  **Decoder (Decodificador):** Tenta reconstruir perfeitamente os dados de entrada originais a partir dessa representa√ß√£o compacta.

**O Processo de Detec√ß√£o:**

1.  **Treinamento:** O Autoencoder √© treinado **exclusivamente com dados 100% normais**. Ele se torna excelente em comprimir e reconstruir a "assinatura" da opera√ß√£o normal, resultando em um **Erro de Reconstru√ß√£o** muito baixo.
2.  **Defini√ß√£o do Limiar (Threshold):** Calculamos o erro m√©dio ($\mu$) e o desvio padr√£o ($\sigma$) dos dados normais. Definimos um limiar estat√≠stico (ex: $\mu + 3\sigma$). Qualquer erro *acima* deste limiar √© considerado estatisticamente improv√°vel de ser "normal".
3.  **Detec√ß√£o:** Quando o modelo treinado recebe um dado novo:
    * **Dado Normal:** O modelo o reconstr√≥i facilmente. O erro fica *abaixo* do limiar. -> **Status: OK.**
    * **Dado An√¥malo:** O modelo (treinado s√≥ em normalidade) falha em reconstru√≠-lo. O erro *dispara* e ultrapassa o limiar. -> **Status: ANOMALIA DETECTADA.**

## 4. O Dashboard Interativo (Streamlit)

O produto final √© um dashboard em `streamlit` que simula um cen√°rio de monitoramento em tempo real. O dashboard:
* Carrega o modelo `autoencoder_model.h5` e o `anomaly_scaler.pkl`.
* Permite que o usu√°rio insira o `threshold` (Limiar) calculado no notebook.
* Simula um streaming de dados (lendo o arquivo `1.csv`, que cont√©m anomalias).
* Plota o Erro de Reconstru√ß√£o em um gr√°fico de linha.
* Exibe um alerta visual (vermelho) e um status de "ANOMALIA DETECTADA" sempre que o erro ultrapassa o limiar.

*(Exemplo do Dashboard em a√ß√£o)*
`![Dashboard de Detec√ß√£o de Anomalias](dashboard_demo.png)`

## 5. Tech Stack (Tecnologias Utilizadas)

* **Dashboard e Visualiza√ß√£o:** Streamlit
* **Deep Learning:** TensorFlow (Keras) (para o Autoencoder LSTM)
* **Manipula√ß√£o de Dados:** Pandas, NumPy
* **Machine Learning:** Scikit-learn (para `MinMaxScaler` e m√©tricas)
* **Serializa√ß√£o:** Joblib

## 6. Estrutura do Projeto

```
[ projeto_deteccao_anomalia/ ]
|
|-- data/
|   |-- raw/          <-- (CSVs do SKAB, ex: '1.csv', '2.csv'...)
|   |-- processed/
|       |-- normal_data_train.csv  <-- (Gerado pelo notebook)
|
|-- dashboard/
|   |-- app.py                  <-- (Script do Streamlit)
|   |-- requirements_dash.txt
|
|-- models/
|   |-- autoencoder_model.h5    <-- (Modelo treinado)
|   |-- anomaly_scaler.pkl      <-- (Scaler treinado)
|
|-- notebooks/
|   |-- 01_EDA_e_Treinamento_Autoencoder.ipynb
|
|-- requirements.txt            <-- (Depend√™ncias do notebook)
|-- README.md
```

## 7. Como Usar

### Pr√©-requisitos
* Python 3.11+
* Ambiente virtual (recomendado)

### Instala√ß√£o
1.  Clone o reposit√≥rio e entre na pasta.
2.  Crie e ative um ambiente virtual.
3.  Instale as depend√™ncias de treinamento:
    ```bash
    pip install -r requirements.txt
    ```
4.  Instale as depend√™ncias do dashboard:
    ```bash
    pip install -r dashboard/requirements_dash.txt
    ```

### Passo 1: Treinar o Modelo
1.  Abra e execute o notebook `notebooks/01_EDA_e_Treinamento_Autoencoder.ipynb`.
2.  Execute todas as c√©lulas (C√©lula 1, 2, 3 e 4).
3.  Ao final da **C√©lula 3**, anote o valor do limiar calculado:
    `Limiar (Œº + 3œÉ): 0.XXXXXX`
    
Isso salvar√° os arquivos `autoencoder_model.h5` e `anomaly_scaler.pkl` na pasta `models/`.

### Passo 2: Executar o Dashboard
1.  No seu terminal, a partir da pasta raiz do projeto, execute o Streamlit:
    ```bash
    streamlit run dashboard/app.py
    ```
2.  O Streamlit abrir√° no seu navegador.
3.  Na barra lateral esquerda, **cole o valor do Limiar (threshold)** que voc√™ anotou.
4.  Clique no bot√£o **"Iniciar Simula√ß√£o üöÄ"**.

Observe o gr√°fico de erro em tempo real e os alertas de anomalia.

## 8. Resultados do Modelo

A avalia√ß√£o do modelo (na C√©lula 4 do notebook) contra os dados completos (incluindo anomalias) produziu os seguintes resultados:

* **Precision (Anomalia): 0.98 (98%)**
    * **Interpreta√ß√£o:** Quando o modelo dispara um alarme de anomalia, ele est√° correto 98% das vezes. Isso √© excelente, pois minimiza "alarmes falsos" (Falsos Positivos).

* **Recall (Anomalia): 0.56 (56%)**
    * **Interpreta√ß√£o:** O modelo conseguiu detectar 56% de todas as anomalias reais presentes nos dados.

* **O Trade-off (Precis√£o vs. Recall):**
    O Recall de 56% √© um resultado direto da nossa escolha de um limiar estat√≠stico rigoroso (3 sigmas), que prioriza a **alta precis√£o**. Em um cen√°rio real, este limiar √© um "bot√£o de sintonia":
    * **Aumentar o Limiar:** Diminui os alarmes falsos (aumenta a precis√£o), mas pode perder falhas sutis (diminui o recall).
    * **Diminuir o Limiar:** Encontra mais falhas (aumenta o recall), mas ao custo de mais alarmes falsos (diminui a precis√£o).
